##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
complexity = complexity + sum(countVector);
}
#Load scripts
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE)
dataframe <- readLines(fileList[1])
for(fileName in fileList){
computeFile(fileName);
}
;
;
#Load scripts
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
complexity
line <- dataframe[1]
line
line
line <- dataframe[2]
line
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|", "\\?", ":","catch", "finally", "throw", "throws");
str_count(line,factors)
str_count(dataframe[3],factors)
str_count(dataframe[4],factors)
str_count(dataframe[4],factors)
str_count(dataframe[5],factors)
line <- dataframe[4]
line
str_count(dataframe[6],factors)
str_count(dataframe[7],factors)
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
str_count(dataframe[7],factors)
dataframe[7]
str_count(dataframe[7],factors)
print(line)
##Process each file
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
complexity = complexity + sum(countVector);
}
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
complexity
##Process each file
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
?print
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
print(complexity);
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
complexity
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
return (complexity);
}
##Process each file
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
return (complexity);
}
#Load scripts
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
print("complexity:"+computeFile(fileName));
}
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
print("complexity:",computeFile(fileName));
}
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
cat("complexity:",computeFile(fileName));
}
?qnorm
qnorm(0.95,0,1,lower.tail = FALSE, log.p = FALSE)
qnorm(95,0,1,lower.tail = FALSE, log.p = FALSE)
qnorm(0.95,0,1,lower.tail = TRUE, log.p = FALSE)
qnorm(0.975,0,1,lower.tail = TRUE, log.p = FALSE)
?dbeta
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,4,0),type="l")
plot(theta,dbeta(theta,4,1),type="l")
plot(theta,dbeta(theta,1,1),type="l")
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,4,2),type="l")
plot(theta,dbeta(theta,0,4),type="l")
?dbeta
plot(theta,dbeta(theta,1,4),type="l")
plot(theta,dbeta(theta,1,5),type="l")
1-pbeta(.25,41,11)
1-pbeta(.5,41,11)
1-pbeta(.8,41,11)
1-pbeta(.5,1,5)
pbeta(.5,1,5)
plot(theta,dbeta(theta,41,11),type="l")
1-pbeta(.5,41,11)
1-pbeta(.8,41,11)
?pbeta
1-pbeta(.8,41,11,lower.tail = TRUE)
1-pbeta(.8,1,5,lower.tail = TRUE)
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,1,5),type="l")
pbeta(.5,1,5)
pbeta(.5,1,5)
1- pbeta(.95,8,16)
1- pbeta(0.95,16,8)
qbeta(0.025,8,16)
qbeta(0.975,8,16)
1-pbeta(.8,41,11)
1-pbeta(.5,41,11)
1-pbeta(.25,41,11)
qbeta(.025,41,11)
qbeta(.975,41,11)
qbeta(0.05,8,16)
qbeta(0.95,8,16)
qbeta(0.90,8,16)
?pbeta
pgamma
pgamma
?pgamma
theta=seq(from=0,to=1,by=.01)
plot(theta,gamma(theta,67,6),type="l")
plot(theta,dgamma(theta,67,6),type="l")
plot(theta,dgamma(theta,8,1),type=".")
plot(theta,dgamma(theta,67,6),type="l")
plot(theta,dgamma(theta,8,1),type="-")
plot(theta,dgamma(theta,8,1),type="-")
lines(theta,dgamma(theta,67,6),lty=2)
lines(theta,dgamma(theta,8,1),lty=3
plot(theta,dbeta(theta,32,20),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
lines(theta,44*dbinom(24,size=40,p=theta),lty=3)
plot(theta,dbeta(theta,32,20),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
source('C:/Users/chris/OneDrive/Documentos/GitHub/bayesianStudies/CredibleIntervals.R', echo=TRUE)
plot(theta,dgamma(theta,8,1),type="l")
lines(theta,dgamma(theta,8,1),lty=3)
lines(theta,dgamma(theta,67,6),lty=2)
gam=seq(from=0,to=20,by=1)
plot(theta,dgamma(gam,8,1),type="l")
lines(theta,dgamma(gam,8,1),lty=3)
lines(theta,dgamma(gam,67,6),lty=2)
plot(theta,dgamma(gam,8,1),type="l")
gam=seq(from=0,to=20,by=1)
plot(theta,dgamma(gam,8,1),type="l")
plot(gam,dgamma(gam,8,1),type="l")
lines(gam,dgamma(gam,8,1),lty=3)
lines(gam,dgamma(gam,67,6),lty=2)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=3)
lines(gam,dgamma(gam,67,6),lty=2)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=2)
lines(gam,dgamma(gam,67,6),lty=3)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=2)
qgamma(0.05,67,6)
qgamma(0.95,67,6)
install.packages('randomForest')
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
dataf = data.frame(data_all);
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- dataf [rowSums(is.na(data))==0,]
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$years_of_programming_experience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$age - dataf$years_of_programming_experience) <5,]
#Remove outliers
dataf <- dataf [!dataf$years_of_programming_experience >40,]
dataf <- dataf [!dataf$age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
dataf =loadAnswers();
source("C://Users//chris//OneDrive//Documentos//GitHub//phonitus_analytics//loadAnswers.R");
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus_analytics//loadAnswers.R");
source("C://Users//chris//OneDrive//Documentos//GitHub//photinusAnalytics//loadAnswers.R");
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- dataf [rowSums(is.na(data_all))==0,]
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$years_of_programming_experience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$age - dataf$years_of_programming_experience) <5,]
#Remove outliers
dataf <- dataf [!dataf$years_of_programming_experience >40,]
dataf <- dataf [!dataf$age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- data_all [rowSums(is.na(data_all))==0,]
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$years_of_programming_experience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$age - dataf$years_of_programming_experience) <5,]
#Remove outliers
dataf <- dataf [!dataf$years_of_programming_experience >40,]
dataf <- dataf [!dataf$age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
dataf = data.frame(data_all);
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- dataf [rowSums(is.na(data_all))==0,]
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$years_of_programming_experience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$age - dataf$years_of_programming_experience) <5,]
#Remove outliers
dataf <- dataf [!dataf$years_of_programming_experience >40,]
dataf <- dataf [!dataf$age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- data_all [rowSums(is.na(data_all))==0,]
summary(dataf)
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$years_of_programming_experience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$age - dataf$years_of_programming_experience) <5,]
#Remove outliers
dataf <- dataf [!dataf$years_of_programming_experience >40,]
dataf <- dataf [!dataf$age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
summary(dataf);
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
summary(data_all)
dataf <- data_all [rowSums(is.na(data_all))==0,]
summary(dataf);
dataf <- dataf [!dataf$years_of_programming_experience <0,]
dataf <- dataf [!dataf$age <18,] ##minimum age to participate
summary(dataf);
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- data_all [rowSums(is.na(data_all))==0,]
summary(dataf);
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$Worker.yearsOfExperience <0,]
dataf <- dataf [!dataf$Worker.age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$Worker.yearsOfExperience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$Worker.age - dataf$Worker.yearsOfExperience) <5,]
#Remove outliers
dataf <- dataf [!dataf$Worker.yearsOfExperience >40,]
dataf <- dataf [!dataf$Worker.agee >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
#Load Answers into a dataframe
#It also removes invalid input and outliers
loadAnswers<- function(){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//");
fileName = "answerList_data.csv";
data_all <- read.csv(fileName,header = TRUE,sep=",");
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with not available data
dataf <- data_all [rowSums(is.na(data_all))==0,]
summary(dataf);
#Remove Invalid age and invalid years of experience
dataf <- dataf [!dataf$Worker.yearsOfExperience <0,]
dataf <- dataf [!dataf$Worker.age <18,] ##minimum age to participate
#Remove people with no experience in programming
dataf <- dataf [!dataf$Worker.yearsOfExperience ==0,]
#Remove people who whose age and experience
dataf <- dataf [!(dataf$Worker.age - dataf$Worker.yearsOfExperience) <5,]
#Remove outliers
dataf <- dataf [!dataf$Worker.yearsOfExperience >40,]
dataf <- dataf [!dataf$Worker.age >80,]
#summary (dataf);
cat("Data successfully loaded. Number of entries:",length(dataf[,1]));
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//photinus-analytics//loadAnswers.R");
dataf =loadAnswers();
QTPTN_df<-subset(dataf,select(Question.id, TP, TN))
QTPTN_df<-subset(dataf,select= c(Question.id, TP, TN)
);
QTPTN_df<-subset(dataf,select= c(Question.ID, TP, TN));
head(QTPTN_df)
TrueCol <- QTPTN_df$TP + QTPTN_df$TN
head(TrueCol)
length(TrueCol)
subsetTPTN_df <-subset(dataf,select= c(Question.ID, TP, TN));
TrueCol <- subsetTPTN_df$TP + subsetTPTN_df$TN;
AccQuestion_df <- cbind(subsetTPTN_df$Question.ID,TrueCol);
head(AccQuestion_df)
summary(AccQuestion_df)
subsetTPTN_df <-subsetTPTN_df$TP + subsetTPTN_df$TN;
summary(subsetTPTN_df)
subsetTPTN_df <-subset(dataf,select= c(Question.ID, TP, TN));
subsetTPTN_df <-TrueCol
head(subsetTPTN_df)
subsetTPTN_df <-subset(dataf,select= c(Question.ID, TP, TN));
TrueCol <- subsetTPTN_df$TP + subsetTPTN_df$TN;
subsetTPTN_df <- data.frame(subsetTPTN_df);
subsetTPTN_df["TueCol"]<-TrueCol
head(subsetTPTN_df)
subsetTPTN_df <-subset(dataf,select= c(Question.ID, TP, TN));
TrueCount <- subsetTPTN_df$TP + subsetTPTN_df$TN;
subsetTPTN_df <- data.frame(subsetTPTN_df);
subsetTPTN_df["TrueCount"]<-TrueCount
install.packages("dplry");
library(dplry)
install.packages('dplry',, dependencies = TRUE);
